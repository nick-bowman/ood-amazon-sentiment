{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1781343c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9105579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaConfig, RobertaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29c0a29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = RobertaConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b04fa286",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaModel(configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23376d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e8e9788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaConfig {\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"bos_token_id\": 0,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"gradient_checkpointing\": false,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"roberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.3.3\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 30522\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87ce0e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fb18691",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaa93d71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 31414, 232, 2]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Hello world\")['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc09c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RobertaForMaskedLM.from_pretrained('roberta-base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72546fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9797e21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-49a460ae4ccd0cd4\n",
      "Reusing dataset json (/sailhome/rmjones/.cache/huggingface/datasets/json/default-49a460ae4ccd0cd4/0.0.0/83d5b3a2f62630efc6b5315f00f20209b4ad91a00ac586597caee3a4da0bef02)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset('json', data_files='/scr/amazon-sentiment/Appliances_5.json.gz', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47797dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['overall', 'verified', 'reviewTime', 'reviewerID', 'asin', 'reviewerName', 'reviewText', 'summary', 'unixReviewTime', 'style', 'vote', 'image'],\n",
       "    num_rows: 2277\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "428c1f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_remove = list(dataset.features.keys())\n",
    "columns_to_remove.remove('reviewText')\n",
    "columns_to_remove.remove('summary')\n",
    "columns_to_remove.remove('overall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "082b604a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['verified',\n",
       " 'reviewTime',\n",
       " 'reviewerID',\n",
       " 'asin',\n",
       " 'reviewerName',\n",
       " 'unixReviewTime',\n",
       " 'style',\n",
       " 'vote',\n",
       " 'image']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e1bc348",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns(columns_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a9efb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96388dbc5c0d4be69561a65126ba503b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2277.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mapped_dataset = dataset.map(lambda row: {'text': row['summary'] + '. ' + row['reviewText']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e7205c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['overall', 'reviewText', 'summary', 'text'],\n",
       "    num_rows: 2277\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6def9a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overall': 3.0,\n",
       " 'reviewText': \"At first this contraption was a little confusing. I read the directions about 3 times before I felt okay about going through with the project - was not fully confident as there were a lot of warnings about making sure the drill was going the right way/you turned it the right way so you wouldn't lose rods in the dryer vent. Scared me a little. However, the project turned out really well. We didn't lose any rods (thankfully) and we got out the birds nest that had taken residence in our dryer vent!!\\nThe part that was for the lint catcher was convenient as well and is actually recommended to be used at least once a month in order to clean out the lint catcher. I do need to keep up with this but it isn't convenient to have to put together and tape the rods each time when you only really use it for a couple of minutes. However, if you have a handy space to keep it already together, I can see how this would be even better for keeping up with cleaning the lint out.\",\n",
       " 'summary': 'Does what it needs to',\n",
       " 'text': \"Does what it needs to. At first this contraption was a little confusing. I read the directions about 3 times before I felt okay about going through with the project - was not fully confident as there were a lot of warnings about making sure the drill was going the right way/you turned it the right way so you wouldn't lose rods in the dryer vent. Scared me a little. However, the project turned out really well. We didn't lose any rods (thankfully) and we got out the birds nest that had taken residence in our dryer vent!!\\nThe part that was for the lint catcher was convenient as well and is actually recommended to be used at least once a month in order to clean out the lint catcher. I do need to keep up with this but it isn't convenient to have to put together and tape the rods each time when you only really use it for a couple of minutes. However, if you have a handy space to keep it already together, I can see how this would be even better for keeping up with cleaning the lint out.\"}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapped_dataset[2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47e7d421",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9d516a2e7c04addbe7095af8a080c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (987 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_dataset = mapped_dataset.map(lambda examples: tokenizer(examples['text']), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a8dac6bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed40506d44447a2a4244b41247544c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_dataset = encoded_dataset.filter(lambda row: len(row['input_ids']) <= 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c528a852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, mlm=True, mlm_probability=0.15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94083a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./roberta-retrained\",\n",
    "    overwrite_output_dir=True,\n",
    "    num_train_epochs=1,\n",
    "    per_device_train_batch_size=48,\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=encoded_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3c1cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6968f930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# align products with reviews\n",
    "reviews = {}\n",
    "summaries = {}\n",
    "for data_file in data_files:\n",
    "    local_reviews = defaultdict(list)\n",
    "    local_summaries = defaultdict(list)\n",
    "    with gzip.open(os.path.join(DATA_HOME, data_file)) as f:\n",
    "        i = 0\n",
    "        for l in tqdm(f):\n",
    "            r = json.loads(l)\n",
    "            local_reviews[int(r['overall'])].append(r['reviewText'].replace(\"\\n\", \"\") if 'reviewText' in r else \"\")\n",
    "            summary = r['summary'] if 'summary' in r else \"\"\n",
    "            summary = summary if summary.strip().endswith('.') else summary + \".\"\n",
    "            local_summaries[int(r['overall'])].append(summary)\n",
    "    reviews[data_file[:data_file.find(\".json.gz\")]] = local_reviews\n",
    "    summaries[data_file[:data_file.find(\".json.gz\")]] = local_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5651ff1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": ".env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
